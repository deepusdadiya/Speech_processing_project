{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io.wavfile as wav\n",
    "from python_speech_features import mfcc\n",
    "from tempfile import TemporaryFile\n",
    "import os\n",
    "import math\n",
    "import pickle\n",
    "import random\n",
    "import operator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function to get distance between feature vectors and find neighbors\n",
    "def getNeighbors(trainingset, instance, k):\n",
    "    #This is a function definition that takes in three arguments: trainingset: a list of training instances (tuples) with labels\n",
    "    #instance: the instance that we want to find the neighbors for k: the number of neighbors we want to find\n",
    "    distances = []\n",
    "    for x in range(len(trainingset)):\n",
    "        dist = distance(trainingset[x], instance, k) + distance(instance,trainingset[x],k)\n",
    "        distances.append((trainingset[x][2], dist))\n",
    "        #This loop calculates the distance between the instance and all the instances in the trainingset.\n",
    "        #For each instance in the trainingset, it calculates the distance by calling the distance function twice:\n",
    "            #distance(trainingset[x], instance, k) calculates the distance between the current trainingset instance and the instance.\n",
    "            #distance(instance,trainingset[x],k) calculates the distance between the instance and the current trainingset instance.\n",
    "        #The two distances are added together to get the total distance between the two instances.\n",
    "        #The label of the current trainingset instance and its distance to the instance are added to the distances list as a tuple.\n",
    "    distances.sort(key=operator.itemgetter(1))\n",
    "    neighbors = []\n",
    "    for x in range(k):\n",
    "        neighbors.append(distances[x][0])\n",
    "        #This loop sorts the distances list by the distance value (the second item in each tuple).\n",
    "    return neighbors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#function to identify the nearest neighbors\n",
    "#This function takes in a list of neighbors (i.e., the labels of the k closest instances to a given instance).\n",
    "#The function then creates a dictionary classVote to keep track of the number of instances with each label.\n",
    "def nearestclass(neighbors):\n",
    "    classVote = {}\n",
    "    #For each label in neighbors, the function checks if it is already in the classVote dictionary. If it is, the count for that label is incremented; otherwise, a new key is added with a count of 1.\n",
    "    for x in range(len(neighbors)):\n",
    "        response = neighbors[x]\n",
    "        if response in classVote:\n",
    "            classVote[response] += 1\n",
    "        else:\n",
    "            classVote[response] = 1\n",
    "    #Now, classVote dictionary is sorted in descending order of counts, using the sorted() function and the operator.itemgetter() method.\n",
    "    #The label with the highest count is returned as the output of the function. This label represents the predicted class for the given instance.       \n",
    "    sorter = sorted(classVote.items(), key=operator.itemgetter(1), reverse=True)\n",
    "    return sorter[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, prediction):\n",
    "    correct = 0\n",
    "    for x in range(len(testSet)):\n",
    "        if testSet[x][-1] == prediction[x]:\n",
    "            correct += 1\n",
    "    return 1.0 * correct / len(testSet)\n",
    "    #For each instance in testSet, the function checks if the predicted label (in prediction[x]) matches the true label \n",
    "    # (which is the last element of the instance, denoted by testSet[x][-1]).\n",
    "    #If the predicted label matches the true label, then the correct count is incremented by 1.\n",
    "    #Once all instances have been checked, the function returns the accuracy of the predictions as a decimal value between 0 and 1. \n",
    "    # This is calculated by dividing the number of correct predictions by the total number of instances in testSet."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blues\n",
      "classical\n",
      "country\n",
      "disco\n",
      "hiphop\n",
      "jazz\n",
      "metal\n",
      "pop\n",
      "reggae\n",
      "rock\n"
     ]
    }
   ],
   "source": [
    "directory = 'C:/Users/DELL/Desktop/Quarter_3/Speech_Processing/Project/Data/genres_original'\n",
    "\n",
    "f = open(\"mydataset.dat\", \"wb\")\n",
    "i = 0\n",
    "for folder in os.listdir(directory):\n",
    "    print(folder)\n",
    "    i += 1\n",
    "    if i == 11:\n",
    "        break\n",
    "    for file in os.listdir(directory+\"/\"+folder):\n",
    "        #print(file)\n",
    "        try:\n",
    "            (rate, sig) = wav.read(directory+\"/\"+folder+\"/\"+file)\n",
    "            #Mel-frequency cepstral coefficients (MFCCs) are computed for each audio file using the mfcc() function from the speech recognition library.\n",
    "            #The mean and covariance of the MFCC features are computed and stored in a tuple along with a label for the genre of the audio file.\n",
    "            mfcc_feat = mfcc(sig, rate, winlen = 0.020, appendEnergy=False)\n",
    "            covariance = np.cov(np.matrix.transpose(mfcc_feat))\n",
    "            mean_matrix = mfcc_feat.mean(0)\n",
    "            feature = (mean_matrix, covariance, i)\n",
    "            pickle.dump(feature, f)\n",
    "        #If an exception is raised during processing of a file, the exception is caught and an error message is printed, \n",
    "        # along with the folder and filename where the exception occurred.\n",
    "        except Exception as e:\n",
    "            print(\"Got an exception: \", e, 'in folder: ', folder, ' filename: ', file)\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = []\n",
    "\n",
    "def loadDataset(filename, split, trset, teset):\n",
    "    #The function opens the binary file specified by the filename using the open() function in binary read mode and reads in the data using pickle.load().\n",
    "    with open('mydataset.dat','rb') as f:\n",
    "        while True:\n",
    "            #The data is appended to the dataset list until the end of the file is reached.\n",
    "            try:\n",
    "                dataset.append(pickle.load(f))\n",
    "            except EOFError:\n",
    "                f.close()\n",
    "                break\n",
    "    #For each item in dataset, a random number between 0 and 1 is generated using the random.random() function. If the number is less than the split ratio, \n",
    "    #the item is added to the training set, otherwise it is added to the test set.\n",
    "    for x in range(len(dataset)):\n",
    "        if random.random() < split:\n",
    "            trset.append(dataset[x])\n",
    "        else:\n",
    "            teset.append(dataset[x])\n",
    "\n",
    "trainingSet = []\n",
    "testSet = []\n",
    "loadDataset('my.dat', 0.68, trainingSet, testSet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function computes the Mahalanobis distance to find similarities between the two instances\n",
    "#The formula for Mahalanobis distance is:\n",
    "#D² = (x - μ)ᵀ Σ⁻¹ (x - μ)\n",
    "def distance(instance1, instance2, k):\n",
    "    distance = 0\n",
    "    mm1 = instance1[0]\n",
    "    cm1 = instance1[1]\n",
    "    mm2 = instance2[0]\n",
    "    cm2 = instance2[1]\n",
    "    distance = np.trace(np.dot(np.linalg.inv(cm2), cm1))\n",
    "    distance += (np.dot(np.dot((mm2-mm1).transpose(), np.linalg.inv(cm2)), mm2-mm1))\n",
    "    distance += np.log(np.linalg.det(cm2)) - np.log(np.linalg.det(cm1))\n",
    "    distance -= k\n",
    "    return distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7194029850746269\n"
     ]
    }
   ],
   "source": [
    "# Make the prediction using KNN(K nearest Neighbors)\n",
    "length = len(testSet)\n",
    "predictions = []\n",
    "#making predictions for each instance in the test set by calling the getNeighbors() function to get the k nearest neighbors in the training set for each instance, \n",
    "# and then calling the nearestclass() function to determine the predicted class based on the majority vote of those neighbors. The value of k used is 5.\n",
    "for x in range(length):\n",
    "    predictions.append(nearestclass(getNeighbors(trainingSet, testSet[x], 5)))\n",
    "#The predicted classes are stored in a list called predictions. The accuracy of the predictions is calculated using the getAccuracy() function by comparing \n",
    "# each predicted class to the actual class in the test set, and returning the proportion of correct predictions.\n",
    "accuracy1 = getAccuracy(testSet, predictions)\n",
    "print(accuracy1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "jazz\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "results = defaultdict(int)\n",
    "#defaultdict class from the collections module to create a dictionary results with integer keys and string values. \n",
    "# The integer keys start from 5 and are incremented by 1 for each folder in the directory.\n",
    "directory = 'C:/Users/DELL/Desktop/Quarter_3/Speech_Processing/Project/Data/genres_original'\n",
    "#Then, the nearestclass function is called with arguments dataset, feature, and 3, which returns a predicted class label. \n",
    "i = 5\n",
    "for folder in os.listdir(directory):\n",
    "    results[i] = folder\n",
    "    i += 1\n",
    "# Finally, the predicted class label is looked up in the results dictionary to get the corresponding genre name, which is printed to the console.\n",
    "pred = nearestclass(getNeighbors(dataset, feature, 3))\n",
    "print(results[pred])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
